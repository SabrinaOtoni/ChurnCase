{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cancelamento de Clientes - Telco (dataset criado pela IBM para demonstração da ferramenta IBM Cognos Analytics)\n",
    "\n",
    "### Contém informações sobre uma empresa fictícia de telecomunicações que forneceu serviços de telefonia residencial e internet para 7043 clientes na Califórnia no 3º trimestre.\n",
    "\n",
    "### Etapa do pipeline - Realizado por Sabrina Otoni da Silva - 2024/01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Objetivo: Testar combinações dos tratamentos desenvolvidos e modelos de Machine Learning com fine-tuning (o refinamento das predições será realizado no próximo passo após escolha do modelo). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler, MinMaxScaler\n",
    "\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "import sys\n",
    "import os\n",
    "\n",
    "automations_dir = os.path.join(os.getcwd(), '../automations')\n",
    "\n",
    "if automations_dir not in sys.path:\n",
    "    sys.path.append(automations_dir)\n",
    "\n",
    "from data_processing import LogTransformer, BoxCoxTransformer, RBFTransformer, KMeansCluster, DropColumns, ServiceTransformer, CategoricalEncoder\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "datapath = Path('../data')\n",
    "csv_path = Path(f'{datapath}/d02_intermediate')\n",
    "preprocesspath = Path('../preprocessing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_csv(f'{csv_path}/X_train.csv')\n",
    "y_train = pd.read_csv(f'{csv_path}/y_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PassthroughTransformer(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_kmeans():\n",
    "    return KMeansCluster(model_path='../preprocessing/kmeans_model.pkl', columns_cluster=['Latitude', 'Longitude'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConditionalServiceTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, encoder_type):\n",
    "        self.service_transformer = ServiceTransformer(columns=['Multiple Lines', 'Online Security', 'Online Backup', 'Device Protection', \n",
    "                                                            'Tech Support', 'Streaming TV', 'Streaming Movies'])\n",
    "        self.encoder_type = encoder_type\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        if self.encoder_type == 'onehot':\n",
    "            self.service_transformer.fit(X, y)\n",
    "            return self\n",
    "        else:\n",
    "            return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        if self.encoder_type == 'onehot':\n",
    "            return self.service_transformer.transform(X)\n",
    "        else:\n",
    "            return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_transformer(transformer_type: str, columns: list = None):\n",
    "    if transformer_type == 'log':\n",
    "        return LogTransformer(model_path='../preprocessing/log_transformer_model.pkl', columns=['Total Charges'])\n",
    "    elif transformer_type == 'boxcox':\n",
    "        return BoxCoxTransformer(model_path='../preprocessing/boxcox_transformer_model.pkl', columns=['Total Charges'])\n",
    "    else:\n",
    "        return PassthroughTransformer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rbf():\n",
    "    return RBFTransformer(model_path='../preprocessing/rbf_transformer_model.pkl', column='Tenure Months') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_pipeline(transformer, cond_encoder_type: str, cat_encoder_type: str, scaler, model):\n",
    "    pipeline_steps = [\n",
    "    ('kmeans_cluster', get_kmeans()),\n",
    "    ('import_drop', DropColumns(drop_columns=[\"City\", \"Latitude\", \"Longitude\", \"ID\"])),\n",
    "    ('service_transformer', ConditionalServiceTransformer(encoder_type=cond_encoder_type)),\n",
    "    ('categorical_encoder', CategoricalEncoder(encoder_type=cat_encoder_type, specified_columns=[\"Gender\", \"Senior Citizen\", \"Partner\", \"Dependents\", \"Phone Service\", \"Multiple Lines\", \"Internet Service\",\n",
    "                                                                  \"Online Security\", \"Online Backup\", \"Device Protection\", \"Tech Support\", \"Streaming TV\", \"Streaming Movies\",\n",
    "                                                                  \"Contract\", \"Paperless Billing\", \"Payment Method\", \"Cluster\"])),\n",
    "    ('transformation', transformer),        \n",
    "    ('rbf', get_rbf()),                                                              \n",
    "    ('scaler', scaler),\n",
    "    ('model', model)\n",
    "    ]\n",
    "    return Pipeline(pipeline_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler_dict = {\n",
    "    'standard': StandardScaler(),\n",
    "    'minmax': MinMaxScaler(),\n",
    "    'robust': RobustScaler()\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dict = {\n",
    "    'dummy': DummyClassifier(strategy='most_frequent'),\n",
    "    'logistic_regression': LogisticRegression(),\n",
    "    'svr': SVR(),\n",
    "    'knn': KNeighborsClassifier(),\n",
    "    'random_forest': RandomForestClassifier(),\n",
    "    'xgboost': XGBClassifier(objective='binary:logistic')\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = build_pipeline(\n",
    "    cond_encoder_type='label',\n",
    "    cat_encoder_type='label',\n",
    "    transformer=get_transformer('log'),\n",
    "    scaler=scaler_dict['minmax'],\n",
    "    model=model_dict['dummy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = [\n",
    "    {\n",
    "        'kmeans_cluster__active': [True],\n",
    "        'service_transformer__encoder_type': ['onehot', 'label'], \n",
    "        'categorical_encoder__encoder_type': ['onehot', 'label'], \n",
    "        'transformation': [get_transformer('log'), get_transformer('boxcox')],\n",
    "        'rbf__active': [True, False],\n",
    "        'scaler': [scaler_dict['standard'], scaler_dict['minmax'], scaler_dict['robust']],\n",
    "        \n",
    "        'model': [model_dict['dummy']]\n",
    "    },\n",
    "    {\n",
    "        'kmeans_cluster__active': [True],\n",
    "        'service_transformer__encoder_type': ['onehot', 'label'], \n",
    "        'categorical_encoder__encoder_type': ['onehot', 'label'], \n",
    "        'transformation': [get_transformer('log'), get_transformer('boxcox')],\n",
    "        'rbf__active': [True, False],\n",
    "        'scaler': [scaler_dict['standard'], scaler_dict['minmax'], scaler_dict['robust']],\n",
    "\n",
    "        'model': [model_dict['logistic_regression']],\n",
    "        'model__C': [0.01, 0.1, 1.0],\n",
    "        'model__fit_intercept': [True, False],\n",
    "        'model__class_weight': ['balanced', None]\n",
    "    },\n",
    "    # {\n",
    "    #     'kmeans_cluster__active': [True],\n",
    "    #     'service_transformer__encoder_type': ['onehot', 'label'], \n",
    "    #     'categorical_encoder__encoder_type': ['onehot', 'label'], \n",
    "    #     'transformation': [get_transformer('log'), get_transformer('boxcox')],\n",
    "    #     'rbf__active': [True, False],\n",
    "    #     'scaler': [scaler_dict['standard'], scaler_dict['minmax'], scaler_dict['robust']],\n",
    "\n",
    "    #     'model': [model_dict['svr']],\n",
    "    #     'model__kernel': ['rbf', 'sigmoid'],\n",
    "    #     'model__C': [0.01, 0.1, 1.0]\n",
    "    # },\n",
    "    # {\n",
    "    #     'kmeans_cluster__active': [True],\n",
    "    #     'service_transformer__encoder_type': ['onehot', 'label'], \n",
    "    #     'categorical_encoder__encoder_type': ['onehot', 'label'], \n",
    "    #     'transformation': [get_transformer('log'), get_transformer('boxcox')],\n",
    "    #     'rbf__active': [True, False],\n",
    "    #     'scaler': [scaler_dict['standard'], scaler_dict['minmax'], scaler_dict['robust']],\n",
    "\n",
    "    #     'model': [model_dict['knn']],\n",
    "    #     'model__weights': ['uniform', 'distance'],\n",
    "    #     'model__p': [1, 2]\n",
    "    # },\n",
    "    # {\n",
    "    #     'kmeans_cluster__active': [True],\n",
    "    #     'service_transformer__encoder_type': ['onehot', 'label'], \n",
    "    #     'categorical_encoder__encoder_type': ['onehot', 'label'], \n",
    "    #     'transformation': [get_transformer('log'), get_transformer('boxcox')],\n",
    "    #     'rbf__active': [True, False],\n",
    "    #     'scaler': [scaler_dict['standard'], scaler_dict['minmax'], scaler_dict['robust']],\n",
    "\n",
    "    #     'model': [model_dict['random_forest']],\n",
    "    #     'model__n_estimators': [100, 200],\n",
    "    #     'model__max_depth': [5, 10, 20, None],\n",
    "    #     'model__max_features': ['sqrt', 'log2', None],\n",
    "    #     'model__min_samples_leaf': [1, 50, 100, 200],\n",
    "    #     'model__class_weight': ['balanced', None]\n",
    "    # },\n",
    "    {\n",
    "        'kmeans_cluster__active': [True],\n",
    "        'service_transformer__encoder_type': ['onehot', 'label'], \n",
    "        'categorical_encoder__encoder_type': ['onehot', 'label'], \n",
    "        'transformation': [get_transformer('log'), get_transformer('boxcox')],\n",
    "        'rbf__active': [True, False],\n",
    "        'scaler': [scaler_dict['standard'], scaler_dict['minmax'], scaler_dict['robust']],\n",
    "\n",
    "        'model': [model_dict['xgboost']],\n",
    "        'model__booster': ['gbtree'],\n",
    "        'model__learning_rate': [0.01, 0.1],\n",
    "        'model__gamma': [0.01, 0.1],\n",
    "        'model__max_depth': [3, 6, 9],\n",
    "        'model__subsample': [0.6, 0.8],\n",
    "        'model__colsample_bytree': [0.6, 0.8]\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Os modelos de classificação escolhidos foram: \n",
    "- DummyClassifier: Modelo baseline, se um modelo mais complexo não performa significativamente melhor do que o DummyClassifier, isso pode indicar que o modelo precisa de mais desenvolvimento, ajuste ou que os dados não são adequados para o problema em questão já que ele não aprende com os dados. Também resolvi esse escolhe-lo pois o conjunto de dados é altamente desbalanceado (uma classe é muito mais frequente que outra) e o Dummy pode ser útil para mostrar como um modelo que sempre prevê a classe mais frequente se comportaria. Sempre bom validar porque modelos mais complexos podem parecer ter alta acurácia simplesmente prevendo sempre a classe dominante. Também servirá para uma análise estatística, pois posso comparar se um modelo tem um desempenho significativamente melhor do que um modelo que não tem capacidade de aprendizado.\n",
    "- LogisticRegression\n",
    "- XGBoost\n",
    "\n",
    "Os outros modelos comentados serveriam para validação também, porém por questões de tempo e poder computacional, estarei deixando de fora do pipeline para o GridSearch processar mais rapidamente (em alguns testes anteriores, vi que o XGBoost se sairia melhor, então por isso estou o escolhendo ao invés do RandomForest, se eu deixasse os dois, que foi uma das minhas tentativas, a otimização exaustiva não daria certo). Caso queira verificar como os outros modelos comportariam nesse case, apenas tire os comentários e rode esse notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O que eu quero atingir com as predições do meu modelo?\n",
    "- Por ser um case voltado a cancelamentos, o que me importa é que meu modelo acerte o máximo possível de clientes que tem grande probabilidade de cancelar. A reflexão para definir isso é a seguinte: é melhor que o modelo classifique que um cliente vai cancelar mesmo que ele não vá ou que ele classifique que não vai cancelar um cliente que vai cancelar? Com isso, defino que prefiro aumentar os falsos positivos do que os falsos negativos. \n",
    "- Para esses tipos de situação, temos dois tipos de métrica que valem ser observadas: precisão e o recall. O trade-off dessas duas métricas é uma consideração importante na escolha de um limiar adequado ao meu modelo. Um alto recall pode ser mais desejável para garantir que todos os casos positivos sejam identificados, por outro lado, uma alta precisão pode ser preferida para evitar os falsos positivos. Em passos posteriores, vou aprofundar nas análises dessa questão, mas acho bom frisar isso.\n",
    "\n",
    "\"First off, it might not be good to just go by recall alone. You can simply achieve a recall of 100% by classifying everything as the positive class. I usually suggest using AUC for selecting parameters, and then finding a threshold for the operating point (say a given precision level) that you are interested in.\" - Vi esse comentário em um fórum, e pesquisando afundo e interpretando pro contexto do problema, defini não utilizar Recall para o GridSearch, e abaixo eu explico, porém, não deixarei de analisar essa métrica extremamente importante na próxima etapa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search = GridSearchCV(estimator=pipeline, param_grid=param_grid, cv=StratifiedKFold().split(X_train, y_train), \n",
    "                           scoring='roc_auc', verbose=2, error_score=\"raise\")\n",
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Algumas observações importantes sobre a montagem do GridSearch para essa situação:\n",
    "\n",
    "- StratifiedKFold foi escolhido para preservar a proporção das classes, permitindo uma avaliação mais precisa e robusta do desempenho do modelo, evitando o viés que pode ocorrer se uma dobra tiver uma distribuição de classes significativamente diferente das outras.\n",
    "- ROC_AUC foi escolhido como métrica para medir a capacidade do modelo de distinguir entre as classes, e no contexto do GridSearch, a otimização dos hiperparâmetros do modelo está direcionada para maximizar sua capacidade de discriminação entre as classes, ao invés de apenas maximizar a precisão geral. Também foi decidido utilizar ROC_AUC ao invés de Recall pois os dados são desbalanceados, e isso poderia afetar no objetivo final, já que (por exemplo) se o modelo classificar tudo como positivo, não haveria nenhum falso negativo, e eu teria um Recall de 1, o que daria uma falsa interpretabilidade de um bom score, no contexto da otimização dos huperparâmetros. Posteriormente, estarei usando todas as métricas para avalidação, mas nesse caso, preferi o ROC_AUC por isso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;kmeans_cluster&#x27;,\n",
       "                 KMeansCluster(columns_cluster=[&#x27;Latitude&#x27;, &#x27;Longitude&#x27;],\n",
       "                               model_path=&#x27;../preprocessing/kmeans_model.pkl&#x27;)),\n",
       "                (&#x27;import_drop&#x27;,\n",
       "                 DropColumns(drop_columns=[&#x27;City&#x27;, &#x27;Latitude&#x27;, &#x27;Longitude&#x27;,\n",
       "                                           &#x27;ID&#x27;])),\n",
       "                (&#x27;service_transformer&#x27;,\n",
       "                 ConditionalServiceTransformer(encoder_type=&#x27;label&#x27;)),\n",
       "                (&#x27;categorical_encoder&#x27;,\n",
       "                 CategoricalEncoder(encoder_type=&#x27;l...\n",
       "                               feature_types=None, gamma=0.01, grow_policy=None,\n",
       "                               importance_type=None,\n",
       "                               interaction_constraints=None, learning_rate=0.1,\n",
       "                               max_bin=None, max_cat_threshold=None,\n",
       "                               max_cat_to_onehot=None, max_delta_step=None,\n",
       "                               max_depth=3, max_leaves=None,\n",
       "                               min_child_weight=None, missing=nan,\n",
       "                               monotone_constraints=None, multi_strategy=None,\n",
       "                               n_estimators=None, n_jobs=None,\n",
       "                               num_parallel_tree=None, random_state=None, ...))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-29\" type=\"checkbox\" ><label for=\"sk-estimator-id-29\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;kmeans_cluster&#x27;,\n",
       "                 KMeansCluster(columns_cluster=[&#x27;Latitude&#x27;, &#x27;Longitude&#x27;],\n",
       "                               model_path=&#x27;../preprocessing/kmeans_model.pkl&#x27;)),\n",
       "                (&#x27;import_drop&#x27;,\n",
       "                 DropColumns(drop_columns=[&#x27;City&#x27;, &#x27;Latitude&#x27;, &#x27;Longitude&#x27;,\n",
       "                                           &#x27;ID&#x27;])),\n",
       "                (&#x27;service_transformer&#x27;,\n",
       "                 ConditionalServiceTransformer(encoder_type=&#x27;label&#x27;)),\n",
       "                (&#x27;categorical_encoder&#x27;,\n",
       "                 CategoricalEncoder(encoder_type=&#x27;l...\n",
       "                               feature_types=None, gamma=0.01, grow_policy=None,\n",
       "                               importance_type=None,\n",
       "                               interaction_constraints=None, learning_rate=0.1,\n",
       "                               max_bin=None, max_cat_threshold=None,\n",
       "                               max_cat_to_onehot=None, max_delta_step=None,\n",
       "                               max_depth=3, max_leaves=None,\n",
       "                               min_child_weight=None, missing=nan,\n",
       "                               monotone_constraints=None, multi_strategy=None,\n",
       "                               n_estimators=None, n_jobs=None,\n",
       "                               num_parallel_tree=None, random_state=None, ...))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-30\" type=\"checkbox\" ><label for=\"sk-estimator-id-30\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KMeansCluster</label><div class=\"sk-toggleable__content\"><pre>KMeansCluster(columns_cluster=[&#x27;Latitude&#x27;, &#x27;Longitude&#x27;],\n",
       "              model_path=&#x27;../preprocessing/kmeans_model.pkl&#x27;)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-31\" type=\"checkbox\" ><label for=\"sk-estimator-id-31\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DropColumns</label><div class=\"sk-toggleable__content\"><pre>DropColumns(drop_columns=[&#x27;City&#x27;, &#x27;Latitude&#x27;, &#x27;Longitude&#x27;, &#x27;ID&#x27;])</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-32\" type=\"checkbox\" ><label for=\"sk-estimator-id-32\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">ConditionalServiceTransformer</label><div class=\"sk-toggleable__content\"><pre>ConditionalServiceTransformer(encoder_type=&#x27;label&#x27;)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-33\" type=\"checkbox\" ><label for=\"sk-estimator-id-33\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">CategoricalEncoder</label><div class=\"sk-toggleable__content\"><pre>CategoricalEncoder(encoder_type=&#x27;label&#x27;,\n",
       "                   specified_columns=[&#x27;Gender&#x27;, &#x27;Senior Citizen&#x27;, &#x27;Partner&#x27;,\n",
       "                                      &#x27;Dependents&#x27;, &#x27;Phone Service&#x27;,\n",
       "                                      &#x27;Multiple Lines&#x27;, &#x27;Internet Service&#x27;,\n",
       "                                      &#x27;Online Security&#x27;, &#x27;Online Backup&#x27;,\n",
       "                                      &#x27;Device Protection&#x27;, &#x27;Tech Support&#x27;,\n",
       "                                      &#x27;Streaming TV&#x27;, &#x27;Streaming Movies&#x27;,\n",
       "                                      &#x27;Contract&#x27;, &#x27;Paperless Billing&#x27;,\n",
       "                                      &#x27;Payment Method&#x27;, &#x27;Cluster&#x27;])</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-34\" type=\"checkbox\" ><label for=\"sk-estimator-id-34\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogTransformer</label><div class=\"sk-toggleable__content\"><pre>LogTransformer(columns=[&#x27;Total Charges&#x27;],\n",
       "               model_path=&#x27;../preprocessing/log_transformer_model.pkl&#x27;)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-35\" type=\"checkbox\" ><label for=\"sk-estimator-id-35\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RBFTransformer</label><div class=\"sk-toggleable__content\"><pre>RBFTransformer(active=False, column=&#x27;Tenure Months&#x27;,\n",
       "               model_path=&#x27;../preprocessing/rbf_transformer_model.pkl&#x27;)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-36\" type=\"checkbox\" ><label for=\"sk-estimator-id-36\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-37\" type=\"checkbox\" ><label for=\"sk-estimator-id-37\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=&#x27;gbtree&#x27;, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=0.6, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=0.01, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=0.1, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=3, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
       "              num_parallel_tree=None, random_state=None, ...)</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('kmeans_cluster',\n",
       "                 KMeansCluster(columns_cluster=['Latitude', 'Longitude'],\n",
       "                               model_path='../preprocessing/kmeans_model.pkl')),\n",
       "                ('import_drop',\n",
       "                 DropColumns(drop_columns=['City', 'Latitude', 'Longitude',\n",
       "                                           'ID'])),\n",
       "                ('service_transformer',\n",
       "                 ConditionalServiceTransformer(encoder_type='label')),\n",
       "                ('categorical_encoder',\n",
       "                 CategoricalEncoder(encoder_type='l...\n",
       "                               feature_types=None, gamma=0.01, grow_policy=None,\n",
       "                               importance_type=None,\n",
       "                               interaction_constraints=None, learning_rate=0.1,\n",
       "                               max_bin=None, max_cat_threshold=None,\n",
       "                               max_cat_to_onehot=None, max_delta_step=None,\n",
       "                               max_depth=3, max_leaves=None,\n",
       "                               min_child_weight=None, missing=nan,\n",
       "                               monotone_constraints=None, multi_strategy=None,\n",
       "                               n_estimators=None, n_jobs=None,\n",
       "                               num_parallel_tree=None, random_state=None, ...))])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8634806918269178"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O melhor modelo foi o XGBoost com um score (ROC_AUC) de 0.86 - isso significa que, na maioria dos limiares de decisão, o modelo tem uma alta taxa de verdadeiros positivos enquanto mantém uma baixa taxa de falsos positivos (que é o nosso objetivo como dito anteriormente). O valor de 0.86 também pode ser interpretado como a probabilidade de que, dado um par aleatório de observações (uma de cada classe), o modelo classificará corretamente a observação da classe positiva com uma pontuação mais alta do que a observação da classe negativa. \n",
    "\n",
    "Um ponto que veremos na próxima etapa, mas adianto aqui, é que quanto mais longe de 0.5 melhor. Um score ROC_AUC de 0.5 é, basicamente, um chute aleatório. Significaria que o modelo não tem capacidade de distinguir entre a classe positiva e a negativa melhor do que simplesmente jogando uma moeda, por exemplo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para tratamento dos dados, seguiremos com os clusters, o LabelEncoder, a transformação logarítimica e o StandardScaler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_results = pd.DataFrame(grid_search.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_categorical_encoder__encoder_type</th>\n",
       "      <th>param_kmeans_cluster__active</th>\n",
       "      <th>param_model</th>\n",
       "      <th>param_rbf__active</th>\n",
       "      <th>param_scaler</th>\n",
       "      <th>param_service_transformer__encoder_type</th>\n",
       "      <th>...</th>\n",
       "      <th>param_model__subsample</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.391582</td>\n",
       "      <td>0.056593</td>\n",
       "      <td>0.132938</td>\n",
       "      <td>0.021243</td>\n",
       "      <td>onehot</td>\n",
       "      <td>True</td>\n",
       "      <td>DummyClassifier(strategy='most_frequent')</td>\n",
       "      <td>True</td>\n",
       "      <td>StandardScaler()</td>\n",
       "      <td>onehot</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'categorical_encoder__encoder_type': 'onehot'...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>0.163052</td>\n",
       "      <td>0.016638</td>\n",
       "      <td>0.105448</td>\n",
       "      <td>0.012171</td>\n",
       "      <td>onehot</td>\n",
       "      <td>True</td>\n",
       "      <td>LogisticRegression()</td>\n",
       "      <td>True</td>\n",
       "      <td>StandardScaler()</td>\n",
       "      <td>label</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'categorical_encoder__encoder_type': 'onehot'...</td>\n",
       "      <td>0.858750</td>\n",
       "      <td>0.862933</td>\n",
       "      <td>0.857959</td>\n",
       "      <td>0.854166</td>\n",
       "      <td>0.871080</td>\n",
       "      <td>0.860978</td>\n",
       "      <td>0.005768</td>\n",
       "      <td>267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1958</th>\n",
       "      <td>0.181935</td>\n",
       "      <td>0.037978</td>\n",
       "      <td>0.082483</td>\n",
       "      <td>0.025461</td>\n",
       "      <td>label</td>\n",
       "      <td>True</td>\n",
       "      <td>XGBClassifier(base_score=None, booster='gbtree...</td>\n",
       "      <td>False</td>\n",
       "      <td>StandardScaler()</td>\n",
       "      <td>label</td>\n",
       "      <td>...</td>\n",
       "      <td>0.8</td>\n",
       "      <td>{'categorical_encoder__encoder_type': 'label',...</td>\n",
       "      <td>0.859884</td>\n",
       "      <td>0.866093</td>\n",
       "      <td>0.861707</td>\n",
       "      <td>0.858520</td>\n",
       "      <td>0.871199</td>\n",
       "      <td>0.863481</td>\n",
       "      <td>0.004628</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0          0.391582      0.056593         0.132938        0.021243   \n",
       "194        0.163052      0.016638         0.105448        0.012171   \n",
       "1958       0.181935      0.037978         0.082483        0.025461   \n",
       "\n",
       "     param_categorical_encoder__encoder_type param_kmeans_cluster__active  \\\n",
       "0                                     onehot                         True   \n",
       "194                                   onehot                         True   \n",
       "1958                                   label                         True   \n",
       "\n",
       "                                            param_model param_rbf__active  \\\n",
       "0             DummyClassifier(strategy='most_frequent')              True   \n",
       "194                                LogisticRegression()              True   \n",
       "1958  XGBClassifier(base_score=None, booster='gbtree...             False   \n",
       "\n",
       "          param_scaler param_service_transformer__encoder_type  ...  \\\n",
       "0     StandardScaler()                                  onehot  ...   \n",
       "194   StandardScaler()                                   label  ...   \n",
       "1958  StandardScaler()                                   label  ...   \n",
       "\n",
       "     param_model__subsample  \\\n",
       "0                       NaN   \n",
       "194                     NaN   \n",
       "1958                    0.8   \n",
       "\n",
       "                                                 params split0_test_score  \\\n",
       "0     {'categorical_encoder__encoder_type': 'onehot'...          0.500000   \n",
       "194   {'categorical_encoder__encoder_type': 'onehot'...          0.858750   \n",
       "1958  {'categorical_encoder__encoder_type': 'label',...          0.859884   \n",
       "\n",
       "     split1_test_score split2_test_score split3_test_score split4_test_score  \\\n",
       "0             0.500000          0.500000          0.500000          0.500000   \n",
       "194           0.862933          0.857959          0.854166          0.871080   \n",
       "1958          0.866093          0.861707          0.858520          0.871199   \n",
       "\n",
       "     mean_test_score std_test_score rank_test_score  \n",
       "0           0.500000       0.000000            2881  \n",
       "194         0.860978       0.005768             267  \n",
       "1958        0.863481       0.004628               1  \n",
       "\n",
       "[3 rows x 29 columns]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_results['param_model'] = gs_results['param_model'].astype(str)\n",
    "best_score = gs_results.loc[gs_results.groupby('param_model')['mean_test_score'].idxmax()].copy()\n",
    "best_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'categorical_encoder__encoder_type': 'label',\n",
       " 'kmeans_cluster__active': True,\n",
       " 'model': XGBClassifier(base_score=None, booster='gbtree', callbacks=None,\n",
       "               colsample_bylevel=None, colsample_bynode=None,\n",
       "               colsample_bytree=0.6, device=None, early_stopping_rounds=None,\n",
       "               enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "               gamma=0.01, grow_policy=None, importance_type=None,\n",
       "               interaction_constraints=None, learning_rate=0.1, max_bin=None,\n",
       "               max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "               max_delta_step=None, max_depth=3, max_leaves=None,\n",
       "               min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "               multi_strategy=None, n_estimators=None, n_jobs=None,\n",
       "               num_parallel_tree=None, random_state=None, ...),\n",
       " 'model__booster': 'gbtree',\n",
       " 'model__colsample_bytree': 0.6,\n",
       " 'model__gamma': 0.01,\n",
       " 'model__learning_rate': 0.1,\n",
       " 'model__max_depth': 3,\n",
       " 'model__subsample': 0.8,\n",
       " 'rbf__active': False,\n",
       " 'scaler': StandardScaler(),\n",
       " 'service_transformer__encoder_type': 'label',\n",
       " 'transformation': LogTransformer(columns=['Total Charges'],\n",
       "                model_path='../preprocessing/log_transformer_model.pkl')}"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelpath = Path('../model')\n",
    "cvspath = Path('../data/d04_models')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'{modelpath}/xgboost_params.txt', 'w') as file:\n",
    "    file.write(str(grid_search.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_score.to_csv(f'{cvspath}/score_models.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
